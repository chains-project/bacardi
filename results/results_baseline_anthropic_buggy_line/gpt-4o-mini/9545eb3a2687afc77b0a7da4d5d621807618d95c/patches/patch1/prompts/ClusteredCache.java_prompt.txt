 You are an Automatic Program Repair (APR) tool specialized in fixing Java code issues caused by breaking dependency updates.
Your task is to analyze the provided code and error message, then propose a patch that can be applied to the client code to resolve the issue.

 Here is the client code that is failing:
```java
/*
 * Copyright (C) 1999-2009 Jive Software. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.jivesoftware.openfire.plugin.util.cache;

import com.hazelcast.core.EntryEvent;
import com.hazelcast.core.EntryListener;
import com.hazelcast.core.IMap;
import com.hazelcast.core.MapEvent;
import com.hazelcast.map.listener.MapListener;
import com.hazelcast.monitor.LocalMapStats;
import org.jivesoftware.openfire.XMPPServer;
import org.jivesoftware.openfire.cluster.ClusteredCacheEntryListener;
import org.jivesoftware.openfire.cluster.NodeID;
import org.jivesoftware.openfire.container.Plugin;
import org.jivesoftware.openfire.container.PluginClassLoader;
import org.jivesoftware.openfire.container.PluginManager;
import org.jivesoftware.util.cache.Cache;
import org.jivesoftware.util.cache.CacheFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.annotation.Nonnull;
import java.io.Serializable;
import java.time.Duration;
import java.time.Instant;
import java.util.Collection;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;

/**
 * Clustered implementation of the Cache interface using Hazelcast.
 *
 */
public class ClusteredCache<K extends Serializable, V extends Serializable> implements Cache<K, V> {

    private final Logger logger;

    private final Set<String> listeners = ConcurrentHashMap.newKeySet();

    /**
     * The map is used for distributed operations such as get, put, etc.
     */
    final IMap<K, V> map;
    private String name;
    private long numberOfGets = 0;

    /**
     * Used to limit the amount of duplicate warnings logged.
     */
    private Instant lastPluginClassLoaderWarning = Instant.EPOCH;
    private final Duration pluginClassLoaderWarningSupression = Duration.ofHours(1);

    /**
     * Create a new cache using the supplied named cache as the actual cache implementation
     *
     * @param name a name for the cache, which should be unique per vm.
     * @param cache the cache implementation
     */
    protected ClusteredCache(final String name, final IMap<K, V> cache) {
        this.map = cache;
        this.name = name;
        logger = LoggerFactory.getLogger(ClusteredCache.class.getName() + "[cache: "+name+"]");
    }

    void addEntryListener(final MapListener listener) {
        listeners.add(map.addEntryListener(listener, false));
    }

    @Override
    public String addClusteredCacheEntryListener(@Nonnull final ClusteredCacheEntryListener<K, V> clusteredCacheEntryListener, final boolean includeValues, final boolean includeEventsFromLocalNode)
    {
        final EntryListener<K, V> listener = new EntryListener<K, V>() {
            @Override
            public void mapEvicted(MapEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing map evicted event of node '{}'", eventNodeId);
                    clusteredCacheEntryListener.mapEvicted(eventNodeId);
                }
            }

            @Override
            public void mapCleared(MapEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing map cleared event of node '{}'", eventNodeId);
                    clusteredCacheEntryListener.mapCleared(eventNodeId);
                }
            }

            @Override
            public void entryUpdated(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry update event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryUpdated((K) event.getKey(), (V) event.getOldValue(), (V) event.getValue(), eventNodeId);
                }
            }

            @Override
            public void entryRemoved(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry removed event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryRemoved((K) event.getKey(), (V) event.getOldValue(), eventNodeId);
                }
            }

            @Override
            public void entryEvicted(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry evicted event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryEvicted((K) event.getKey(), (V) event.getOldValue(), eventNodeId);
                }
            }

            @Override
            public void entryAdded(EntryEvent event) {
                if (includeEventsFromLocalNode || !event.getMember().localMember()) {
                    final NodeID eventNodeId = ClusteredCacheFactory.getNodeID(event.getMember());
                    logger.trace("Processing entry added event of node '{}' for key '{}'", eventNodeId, event.getKey());
                    clusteredCacheEntryListener.entryAdded((K) event.getKey(), (V) event.getValue(), eventNodeId);
                }
            }
        };

        final String listenerId = map.addEntryListener(listener, includeValues);
        listeners.add(listenerId);
        logger.debug("Added new clustered cache entry listener (including values: {}, includeEventsFromLocalNode: {}) using ID: '{}'", includeValues, includeEventsFromLocalNode, listenerId);
        return listenerId;
    }

    @Override
    public void removeClusteredCacheEntryListener(@Nonnull final String listenerId) {
        logger.debug("Removing clustered cache entry listener: '{}'", listenerId);
        map.removeEntryListener(listenerId);
        listeners.remove(listenerId);
    }

    @Override
    public String getName() {
        return name;
    }

    @Override
    public void setName(final String name) {
        this.name = name;
    }

    @Override
    public V put(final K key, final V object) {
        if (object == null) { return null; }
        checkForPluginClassLoader(key);
        checkForPluginClassLoader(object);
        return map.put(key, object);
    }

    @Override
    public V get(final Object key) {
        numberOfGets++;
        return map.get(key);
    }

    @Override
    public V remove(final Object key) {
        return map.remove(key);
    }

    @Override
    public void clear() {
        map.clear();
    }

    @Override
    public int size() {
        final LocalMapStats stats = map.getLocalMapStats();
        return (int) (stats.getOwnedEntryCount() + stats.getBackupEntryCount());
    }

    @Override
    public boolean containsKey(final Object key) {
        return map.containsKey(key);
    }

    @Override
    public boolean containsValue(final Object value) {
        return map.containsValue(value);
    }

    @Override
    public Set<Map.Entry<K, V>> entrySet() {
        return map.entrySet();
    }

    @Override
    public boolean isEmpty() {
        return map.isEmpty();
    }

    @Override
    public Set<K> keySet() {
        return map.keySet();
    }

    @Override
    public void putAll(final Map<? extends K, ? extends V> entries) {
        map.putAll(entries);

        // Instances are likely all loaded by the same class loader. For resource usage optimization, let's test just one, not all.
        entries.entrySet().stream().findAny().ifPresent(
            e -> {
                checkForPluginClassLoader(e.getKey());
                checkForPluginClassLoader(e.getValue());
            }
        );
    }

    @Override
    public Collection<V> values() {
        return map.values();
    }

    @Override
    public long getCacheHits() {
        return map.getLocalMapStats().getHits();
    }

    @Override
    public long getCacheMisses() {
        final long hits = map.getLocalMapStats().getHits();
        return numberOfGets > hits ? numberOfGets - hits : 0;
    }

    @Override
    public int getCacheSize() {
        return (int) getLongCacheSize();
    }

    @Override
    public long getLongCacheSize() {
        final LocalMapStats stats = map.getLocalMapStats();
        return stats.getOwnedEntryMemoryCost() + stats.getBackupEntryMemoryCost();
    }

    @Override
    public long getMaxCacheSize() {
        return CacheFactory.getMaxCacheSize(getName());
    }

    @Override
    public void setMaxCacheSize(int i) {
        setMaxCacheSize((long) i);
    }

    @Override
    public void setMaxCacheSize(final long maxSize) {
        CacheFactory.setMaxSizeProperty(getName(), maxSize);
    }

    @Override
    public long getMaxLifetime() {
        return CacheFactory.getMaxCacheLifetime(getName());
    }

    @Override
    public void setMaxLifetime(final long maxLifetime) {
        CacheFactory.setMaxLifetimeProperty(getName(), maxLifetime);
    }

    void destroy() {
        listeners.forEach(map::removeEntryListener);
        map.destroy();
    }

    boolean lock(final K key, final long timeout) {
        boolean result = true;
        if (timeout < 0) {
            map.lock(key);
        } else if (timeout == 0) {
            result = map.tryLock(key);
        } else {
            try {
                result = map.tryLock(key, timeout, TimeUnit.MILLISECONDS);
            } catch (final InterruptedException e) {
                logger.error("Failed to get cluster lock", e);
                result = false;
            }
        }
        return result;
    }

    void unlock(final K key) {
        try {
            map.unlock(key);
        } catch (final IllegalMonitorStateException e) {
            logger.error("Failed to release cluster lock", e);
        }
    }

    /**
     * Clustered caches should not contain instances of classes that are provided by Openfire plugins. These will cause
     * issues related to class loading when the providing plugin is reloaded. This method verifies if an instance is
     * loaded by a plugin class loader, and logs a warning to the log files when it is. The amount of warnings logged is
     * limited by a time interval.
     *
     * @param o the instance for which to verify the class loader
     * @see <a href="https://github.com/igniterealtime/openfire-hazelcast-plugin/issues/74">Issue #74: Warn against usage of plugin-provided classes in Hazelcast</a>
     */
    protected void checkForPluginClassLoader(final Object o) {
        if (o != null && o.getClass().getClassLoader() instanceof PluginClassLoader
            && lastPluginClassLoaderWarning.isBefore(Instant.now().minus(pluginClassLoaderWarningSupression)) )
        {
            // Try to determine what plugin loaded the offending class.
            String pluginName = null;
            try {
                final Collection<Plugin> plugins = XMPPServer.getInstance().getPluginManager().getPlugins();
                for (final Plugin plugin : plugins) {
                    final PluginClassLoader pluginClassloader = XMPPServer.getInstance().getPluginManager().getPluginClassloader(plugin);
                    if (o.getClass().getClassLoader().equals(pluginClassloader)) {
                        pluginName = XMPPServer.getInstance().getPluginManager().getCanonicalName(plugin);
                        break;
                    }
                }
            } catch (Exception e) {
                logger.debug("An exception occurred while trying to determine the plugin class loader that loaded an instance of {}", o.getClass(), e);
            }
            logger.warn("An instance of {} that is loaded by {} has been added to the cache. " +
                "This will cause issues when reloading the plugin that provides this class. The plugin implementation should be modified.",
                o.getClass(), pluginName != null ? pluginName : "a PluginClassLoader");
            lastPluginClassLoaderWarning = Instant.now();
        }
    }
}

```

 the error is triggered in the following specific lines in the previous code:

```java
final IMap<K, V> map;
```
```java
import com.hazelcast.core.IMap;
```
```java
protected ClusteredCache(final String name, final IMap<K, V> cache) {
```
```java
import com.hazelcast.monitor.LocalMapStats;
```
```java
import com.hazelcast.core.MapEvent;
```


 And here is the error message:
[ERROR] /openfire-hazelcast-plugin/src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[58,11] cannot find symbol
  symbol:   class IMap
  location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCache<K,V>

[ERROR] /openfire-hazelcast-plugin/src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[20,26] cannot find symbol
  symbol:   class IMap
  location: package com.hazelcast.core

[ERROR] /openfire-hazelcast-plugin/src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[74,55] cannot find symbol
  symbol:   class IMap
  location: class org.jivesoftware.openfire.plugin.util.cache.ClusteredCache<K,V>

[ERROR] /openfire-hazelcast-plugin/src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[23,29] package com.hazelcast.monitor does not exist

[ERROR] /openfire-hazelcast-plugin/src/java/org/jivesoftware/openfire/plugin/util/cache/ClusteredCache.java:[21,26] cannot find symbol
  symbol:   class MapEvent
  location: package com.hazelcast.core



 Before proposing a fix, please analyze the error message and client code. Wrap your analysis inside <code_analysis> tags:

<code_analysis>
1. Examine the error message:
   - Identify the specific issue related to the dependency update.
   - Note the line number or method where the error occurs.
   - Determine which dependency and version is causing the issue.

2. Review the client code:
   - Locate the problematic areas mentioned in the error message.
   - Identify any related code that might be affected by the changes.

3. Consider potential fixes that adhere to the following constraints:
   - Do not change any function signatures.
   - Only remove the @Override annotation if the method no longer overrides a method in the updated dependency version.
   - Ensure correct imports are used, considering the newer dependency version.
   - Avoid removing existing code unless it directly causes a compilation or functionality error.

4. Plan the necessary changes to fix the issue:
   - List the specific modifications required.
   - Consider potential side effects of the proposed changes.
   - Ensure the fix addresses the root cause of the error.
</code_analysis>

Based on your analysis, propose a patch to fix the issue. Your response should be a complete and compilable Java class in a fenced code block. Adhere to these guidelines:

1. Do not change any function signatures.
2. You may create variables if it simplifies the code.
3. Remove the @Override annotation only if the method no longer overrides a method in the updated dependency version.
4. If fixing the issue requires addressing missing imports, ensure the correct package or class is used in accordance with the newer dependency version.
5. Avoid removing any existing code unless it directly causes a compilation or functionality error.
6. Ensure the entire class is included and that it will compile correctly. Don't use the comment "// ... (rest of the class remains unchanged)".

Please provide your fixed class in the following format:

```java
// Your complete, fixed Java class here
```

Remember to focus specifically on issues related to the dependency update when proposing your fix.
 